# Demo Scenario: Test Case Flow for Judges

This document provides step-by-step test scenarios that judges can follow to evaluate AgentOps.

## Test Scenario 1: High Error Rate Detection & Rollback

### Scenario Overview
Simulate a bad deployment that causes error rate spike ‚Üí AI detects issue ‚Üí System automatically rolls back to stable version.

### Flow Diagram

```mermaid
flowchart TD
    Start([Start Demo]) --> OpenDash[Open Dashboard<br/>Verify all services healthy]
    OpenDash --> Screenshot1[üì∏ Screenshot: All Green]

    Screenshot1 --> InjectFault[Click 'Inject Fault' button<br/>on demo-app-a]
    InjectFault --> FaultActive{Fault Type?}

    FaultActive -->|5xx Errors| SetError[demo-app-a returns<br/>HTTP 500 for 50% requests]
    SetError --> Wait1[‚è±Ô∏è Wait 2-3 minutes<br/>for scheduled scan]

    Wait1 --> Scan[Cloud Scheduler triggers<br/>POST /health/scan]
    Scan --> Detect[Supervisor API detects:<br/>error_rate: 5.2% > threshold 2%]

    Detect --> Screenshot2[üì∏ Screenshot: Service shows Warning]
    Screenshot2 --> AIAnalysis[Gemini AI analyzes incident<br/>2-5 seconds]

    AIAnalysis --> ShowIncident[Dashboard shows new incident:<br/>'High Error Rate Detected'<br/>Status: Action Pending]
    ShowIncident --> Screenshot3[üì∏ Screenshot: Incident appears]

    Screenshot3 --> PubSub[Pub/Sub delivers action<br/>to Fixer Agent]
    PubSub --> Remediate[Fixer Agent executes:<br/>Rollback to previous revision]

    Remediate --> StatusUpdate[Incident status changes:<br/>Action Pending ‚Üí Remediating]
    StatusUpdate --> Screenshot4[üì∏ Screenshot: Remediating status]

    StatusUpdate --> Execute[Cloud Run traffic shifted<br/>100% to stable revision]
    Execute --> Wait2[‚è±Ô∏è Wait 30 seconds<br/>for verification]

    Wait2 --> Verify[System verifies:<br/>error_rate: 0.3% ‚úì]
    Verify --> Resolved[Incident status ‚Üí Resolved<br/>MTTR: 2m 45s]

    Resolved --> Screenshot5[üì∏ Screenshot: Resolved incident<br/>Service healthy again]
    Screenshot5 --> Analytics[Analytics dashboard shows:<br/>Total incidents: 1<br/>Resolved: 1<br/>Success rate: 100%<br/>Avg MTTR: 2.75 min]

    Analytics --> Screenshot6[üì∏ Screenshot: Analytics view]
    Screenshot6 --> ClickIncident[Click incident card<br/>to view details]

    ClickIncident --> Modal[Modal slides in showing:<br/>- AI explanation<br/>- Timeline<br/>- Metrics graph<br/>- Error logs]
    Modal --> Screenshot7[üì∏ Screenshot: Incident details modal]

    Screenshot7 --> End([Demo Complete ‚úì])

    style Start fill:#e1f5ff
    style End fill:#c8e6c9
    style Screenshot1 fill:#fff3e0
    style Screenshot2 fill:#fff3e0
    style Screenshot3 fill:#fff3e0
    style Screenshot4 fill:#fff3e0
    style Screenshot5 fill:#fff3e0
    style Screenshot6 fill:#fff3e0
    style Screenshot7 fill:#fff3e0
    style AIAnalysis fill:#f3e5f5
    style Remediate fill:#ffebee
```

### Expected Outputs at Each Step

#### Step 1: Healthy Dashboard
```
Services Section:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ demo-app-a      ‚îÇ
‚îÇ üü¢ Healthy      ‚îÇ
‚îÇ Error Rate: 0.2%‚îÇ
‚îÇ Latency: 245ms  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Incidents Section:
"No incidents detected - All services are healthy! üéâ"
```

#### Step 2: After Fault Injection
```
Fault Injection API Response:
{
  "status": "fault_injected",
  "fault_type": "5xx_errors",
  "duration": "5 minutes",
  "description": "Returning 500 errors for 50% of requests"
}

Note: Dashboard won't show changes immediately - must wait for next scheduled scan
```

#### Step 3: Detection (2-3 minutes later)
```
Services Section:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ demo-app-a      ‚îÇ
‚îÇ üü° Warning      ‚îÇ  ‚Üê Color changed
‚îÇ Error Rate: 5.2%‚îÇ  ‚Üê Above threshold
‚îÇ Latency: 312ms  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Cloud Logs (supervisor-api):
INFO: Anomaly detected for demo-app-a
INFO: error_rate=5.2% exceeds threshold=2.0%
INFO: Triggering AI analysis...
```

#### Step 4: AI Analysis Complete
```
Cloud Logs (supervisor-api):
INFO: Gemini analysis complete
{
  "root_cause": "Recent deployment rev-003 shows correlation with error spike",
  "recommendation": {
    "action": "ROLLBACK",
    "target_revision": "rev-002",
    "confidence": 0.87
  },
  "explanation": "Error logs indicate database connection timeouts starting at 14:42:15 UTC, coinciding with deployment of revision rev-003..."
}

INFO: Incident created: inc_20250110_144230
INFO: Publishing remediation action to Pub/Sub
```

#### Step 5: Incident Appears in Dashboard
```
Recent Incidents:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üî¥ demo-app-a - High Error Rate        ‚îÇ
‚îÇ Status: [üîÑ Remediating]               ‚îÇ
‚îÇ                                        ‚îÇ
‚îÇ üìä Error rate spike: 5.2% (‚Üë from 0.2%)‚îÇ
‚îÇ ü§ñ AI Recommendation: Rollback to      ‚îÇ
‚îÇ    previous revision                   ‚îÇ
‚îÇ    Confidence: ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 87%   ‚îÇ
‚îÇ                                        ‚îÇ
‚îÇ üìÖ Detected: 1 minute ago              ‚îÇ
‚îÇ ‚è±Ô∏è MTTR: 00:01:15 (ongoing)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Step 6: Remediation Executing
```
Cloud Logs (fixer-agent):
INFO: Received remediation action: inc_20250110_144230
INFO: Updating incident status: action_pending ‚Üí remediating
INFO: Executing action: ROLLBACK
INFO: Service: demo-app-a
INFO: Target revision: demo-app-a-rev-002
INFO: Shifting traffic: rev-003 (0%) ‚Üí rev-002 (100%)
INFO: Cloud Run API response: success
INFO: Waiting 30s for metrics to stabilize...
```

#### Step 7: Verification & Resolution
```
Cloud Logs (fixer-agent):
INFO: Verification check starting
INFO: Current error_rate: 0.3% ‚úì (below threshold)
INFO: Remediation successful!
INFO: Updating incident status: remediating ‚Üí resolved
INFO: MTTR calculated: 165 seconds (2m 45s)

Dashboard Update:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üü¢ demo-app-a - High Error Rate        ‚îÇ
‚îÇ Status: [‚úì Resolved]                   ‚îÇ
‚îÇ                                        ‚îÇ
‚îÇ ‚úÖ Action: Rollback to rev-002         ‚îÇ
‚îÇ üìÖ Detected: 3 minutes ago             ‚îÇ
‚îÇ üìÖ Resolved: 15 seconds ago            ‚îÇ
‚îÇ ‚è±Ô∏è MTTR: 00:02:45                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Services Section:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ demo-app-a      ‚îÇ
‚îÇ üü¢ Healthy      ‚îÇ  ‚Üê Back to green
‚îÇ Error Rate: 0.3%‚îÇ  ‚Üê Normal levels
‚îÇ Latency: 248ms  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### Step 8: Analytics Dashboard
```
Analytics Section:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Total   ‚îÇ ‚îÇ Resolved ‚îÇ ‚îÇ  Failed  ‚îÇ ‚îÇ Pending  ‚îÇ
‚îÇ    1     ‚îÇ ‚îÇ    1     ‚îÇ ‚îÇ    0     ‚îÇ ‚îÇ    0     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Avg MTTR       ‚îÇ  ‚îÇ Success Rate   ‚îÇ
‚îÇ                ‚îÇ  ‚îÇ                ‚îÇ
‚îÇ   2.8 min      ‚îÇ  ‚îÇ    100%        ‚îÇ
‚îÇ                ‚îÇ  ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Incidents by Service (Bar Chart):
demo-app-a:  ‚ñà 1 resolved
demo-app-b:  (no incidents)
```

#### Step 9: Incident Details Modal
```
When clicking the incident card, modal slides in from right:

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚Üê Close    Incident Details             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                         ‚îÇ
‚îÇ üî¥ HIGH ERROR RATE DETECTED             ‚îÇ
‚îÇ demo-app-a                              ‚îÇ
‚îÇ [‚úì Resolved]                            ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ üìä Metrics                              ‚îÇ
‚îÇ Error Rate:    5.2% ‚Üí 0.3%             ‚îÇ
‚îÇ Latency P95:   312ms                   ‚îÇ
‚îÇ Request Count: 1,234/min               ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ ü§ñ AI Analysis                          ‚îÇ
‚îÇ Root Cause: Recent deployment rev-003  ‚îÇ
‚îÇ shows correlation with error spike.    ‚îÇ
‚îÇ Database connection timeouts detected.  ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ Recommendation: Rollback to rev-002     ‚îÇ
‚îÇ Confidence: 87%                         ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ ‚è±Ô∏è Timeline                             ‚îÇ
‚îÇ 14:42:30  üî¥ Anomaly Detected          ‚îÇ
‚îÇ 14:42:35  ü§ñ AI Analysis Complete      ‚îÇ
‚îÇ 14:42:40  üîÑ Rollback Started          ‚îÇ
‚îÇ 14:43:10  ‚è≥ Verification...           ‚îÇ
‚îÇ 14:45:15  ‚úì Resolved                   ‚îÇ
‚îÇ                                         ‚îÇ
‚îÇ üìã Error Logs (Last 5)                  ‚îÇ
‚îÇ [ERROR] Connection timeout: db-pool     ‚îÇ
‚îÇ [ERROR] Failed to acquire connection    ‚îÇ
‚îÇ [ERROR] Request timeout after 10s       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Test Scenario 2: High Latency & Auto-Scaling

### Scenario Overview
Simulate latency spike due to insufficient capacity ‚Üí AI recommends scaling ‚Üí System increases instances.

### Flow Diagram

```mermaid
flowchart TD
    Start([Start Test 2]) --> Reset[Ensure previous test cleaned up<br/>All services healthy]

    Reset --> Inject2[Click 'Inject Fault' button<br/>Select: Latency Spike]
    Inject2 --> LatencySet[demo-app-b now has<br/>2-second response delay]

    LatencySet --> Wait3[‚è±Ô∏è Wait for scan<br/>2-3 minutes]
    Wait3 --> Detect2[Detected: latency_p95: 2.1s<br/>Threshold: 1.0s]

    Detect2 --> AI2[AI Analysis:<br/>High latency + low instances<br/>‚Üí Recommend SCALE_UP]
    AI2 --> Action2[Fixer Agent increases:<br/>min_instances: 1 ‚Üí 3<br/>max_instances: 10 ‚Üí 15]

    Action2 --> Verify2[More instances = more capacity<br/>latency_p95: 0.4s ‚úì]
    Verify2 --> Resolved2[Incident resolved<br/>MTTR: 3m 12s]

    Resolved2 --> Analytics2[Analytics now shows:<br/>Total: 2 incidents<br/>Resolved: 2<br/>Success rate: 100%<br/>Avg MTTR: 2.95 min]

    Analytics2 --> Chart[Bar chart shows incidents<br/>for both demo-app-a and demo-app-b]
    Chart --> End2([Test 2 Complete ‚úì])

    style Start fill:#e1f5ff
    style End2 fill:#c8e6c9
    style AI2 fill:#f3e5f5
    style Action2 fill:#ffebee
```

### Expected Key Outputs

```
AI Recommendation:
{
  "action": "SCALE_UP",
  "parameters": {
    "min_instances": 3,
    "max_instances": 15
  },
  "reasoning": "High latency (2.1s) with only 1 instance. Scaling up will distribute load and reduce response times.",
  "confidence": 0.82
}

Fixer Agent Execution:
INFO: Executing SCALE_UP action
INFO: Current config: min=1, max=10
INFO: New config: min=3, max=15
INFO: Cloud Run update successful
INFO: New instances spinning up...
INFO: Verification: latency_p95=0.4s ‚úì
```

---

## Test Scenario 3: Dark Mode & UI Features

### Flow Diagram

```mermaid
flowchart TD
    Start3([Start UI Test]) --> Light[Dashboard in light mode<br/>White background]

    Light --> Toggle[Click üåô Dark Mode toggle<br/>in header]
    Toggle --> Dark[Dashboard switches to dark mode<br/>Dark gray background<br/>White text]

    Dark --> Persist[Refresh page<br/>Dark mode persists<br/>via localStorage]

    Persist --> Filter[Test auto-refresh:<br/>Watch 'Last update' timestamp<br/>Updates every 10 seconds]

    Filter --> Skeleton[Disable network in DevTools<br/>See loading skeletons<br/>with shimmer effect]

    Skeleton --> Responsive[Resize browser window:<br/>Mobile: 1 column<br/>Tablet: 2 columns<br/>Desktop: 3 columns]

    Responsive --> Animation[Click incident card<br/>Modal slides in from right<br/>with smooth animation]

    Animation --> Close[Click 'Close' or backdrop<br/>Modal slides out]

    Close --> End3([UI Test Complete ‚úì])

    style Start3 fill:#e1f5ff
    style End3 fill:#c8e6c9
    style Dark fill:#37474f,color:#fff
```

---

## Test Scenario 4: Manual Scan Trigger

### Quick Flow

```mermaid
flowchart LR
    A[Dashboard] --> B[Click 'Trigger Scan' button]
    B --> C[Loading spinner appears]
    C --> D[POST /health/scan]
    D --> E[Alert: '3 services scanned,<br/>1 anomaly detected']
    E --> F[Services & incidents refresh<br/>immediately]

    style A fill:#e1f5ff
    style F fill:#c8e6c9
```

---

## Judge Evaluation Checklist

### Technical Evaluation

- [ ] **Cloud Run Integration**: Services deployed on Cloud Run ‚úì
- [ ] **Event-Driven Architecture**: Pub/Sub used for async messaging ‚úì
- [ ] **AI Integration**: Gemini 1.5 Flash for analysis ‚úì
- [ ] **Data Persistence**: Firestore for incident storage ‚úì
- [ ] **Monitoring Integration**: Cloud Monitoring & Logging ‚úì
- [ ] **Automated Remediation**: Rollback & scaling without human intervention ‚úì
- [ ] **Audit Trail**: Complete incident history with MTTR ‚úì

### User Experience

- [ ] **Visual Dashboard**: Clean, modern UI with Tailwind CSS ‚úì
- [ ] **Real-time Updates**: 10-second auto-refresh ‚úì
- [ ] **Dark Mode**: Toggle works and persists ‚úì
- [ ] **Responsive Design**: Works on mobile/tablet/desktop ‚úì
- [ ] **Loading States**: Skeleton screens with shimmer ‚úì
- [ ] **Animations**: Smooth modal transitions (Framer Motion) ‚úì
- [ ] **Data Visualization**: Charts showing analytics (Recharts) ‚úì

### Innovation

- [ ] **AI-Powered Decisions**: Not just rule-based thresholds ‚úì
- [ ] **Confidence Scoring**: AI provides confidence in recommendations ‚úì
- [ ] **Contextual Analysis**: Uses metrics + logs + revisions ‚úì
- [ ] **Closed-Loop System**: Detects ‚Üí Analyzes ‚Üí Acts ‚Üí Verifies ‚úì
- [ ] **Production-Ready**: Safety limits, dry-run mode, audit trail ‚úì

### Reliability

- [ ] **Error Handling**: Graceful degradation if APIs fail ‚úì
- [ ] **Retry Logic**: Exponential backoff for transient failures ‚úì
- [ ] **Idempotency**: Actions can be safely retried ‚úì
- [ ] **Monitoring**: Can detect and fix itself (meta-monitoring) ‚úì

### Documentation

- [ ] **Clear README**: Problem, solution, architecture ‚úì
- [ ] **Architecture Diagrams**: Visual system overview ‚úì
- [ ] **Demo Instructions**: Step-by-step test scenarios ‚úì
- [ ] **API Documentation**: Component READMEs with endpoints ‚úì
- [ ] **Deployment Guide**: One-command setup ‚úì

---

## Common Issues & Troubleshooting

### Issue 1: Fault injection doesn't trigger detection immediately
**Why**: Detection runs every 2 minutes via Cloud Scheduler
**Solution**: Wait 2-3 minutes or click "Trigger Scan" button for immediate scan

### Issue 2: Dashboard shows "Failed to fetch services"
**Why**: Supervisor API not reachable or NEXT_PUBLIC_SUPERVISOR_API_URL not set
**Solution**: Check environment variable, verify supervisor-api is deployed

### Issue 3: Incident stays in "remediating" status
**Why**: Fixer agent may not have received Pub/Sub message
**Solution**: Check Cloud Logs for fixer-agent, verify Pub/Sub subscription active

### Issue 4: Rollback executed but metrics still bad
**Why**: May take 30-60 seconds for metrics to stabilize
**Solution**: Wait another minute, check Cloud Run console for traffic split

### Issue 5: No AI explanation in incident
**Why**: Gemini API may have rate limits or quota exceeded
**Solution**: Check Cloud Logs for gemini API errors, verify Vertex AI quota

---

## Recording the Demo

### Recommended Flow for Video

1. **Introduction (0:00-0:30)**
   - Show healthy dashboard
   - Explain 3 services monitoring demo-app-a, demo-app-b
   - Point out key features: service cards, incident section, analytics

2. **Fault Injection (0:30-0:45)**
   - Click "Inject Fault" on demo-app-a
   - Show confirmation message
   - Explain what will happen next

3. **Detection & Analysis (0:45-2:00)**
   - Wait/fast-forward to next scan
   - Show service turning yellow/red
   - Show incident appearing with "Action Pending" status
   - Open Cloud Logs to show AI analysis (optional)

4. **Automated Remediation (2:00-2:30)**
   - Show status changing to "Remediating"
   - Open Cloud Run console to show traffic shift (optional)
   - Show status changing to "Resolved"
   - Service back to green

5. **Analytics & Details (2:30-3:00)**
   - Scroll to analytics section
   - Show MTTR, success rate, chart
   - Click incident to open modal
   - Highlight AI explanation, timeline, metrics

6. **Conclusion (3:00-3:15)**
   - Summarize: Detected in 2 min, resolved in <3 min
   - Compare to manual process (15-30 min)
   - Emphasize AI-powered, fully automated, production-ready

### Recording Tips
- Use 1920x1080 resolution
- Use browser zoom to make text readable
- Pause at key screenshots
- Use slow mouse movements for clarity
- Add voiceover explaining each step
- Keep total video under 3 minutes

---

## Success Metrics for Judges

After running all test scenarios, judges should see:

```
Analytics Dashboard:
- Total Incidents: 2-3
- Resolved: 2-3 (100%)
- Failed: 0
- Average MTTR: 2-3 minutes

Compare to Manual Response:
- Manual MTTR: 15-30 minutes
- AgentOps MTTR: 2-3 minutes
- Improvement: 90% reduction

Business Impact:
- Reduced on-call burden (handles common issues automatically)
- Faster recovery (< 3 min vs 15-30 min)
- Complete audit trail for compliance
- Cost savings (automated vs human time)
```

This demonstrates a production-ready, AI-powered solution that significantly improves Cloud Run operations.
